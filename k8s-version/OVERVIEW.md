# Kubernetes Version - Overview

Complete Kubernetes/containerized deployment package for the Linux MCP Server Chatbot.

## ğŸ¯ What's Included

This directory contains everything needed to deploy the chatbot on:
- âœ… **Kubernetes** (vanilla, any distro)
- âœ… **OpenDataHub** (community AI/ML platform)
- âœ… **Red Hat OpenShift AI** (enterprise AI platform)
- âœ… **OpenShift** (Red Hat container platform)

## ğŸ“¦ Package Contents

### 1. Container Image (`docker/`)

- **Dockerfile** - Multi-architecture (amd64/arm64) container image
- **build.sh** - Automated build script
- **.dockerignore** - Build optimizations

**Features:**
- Non-root user (UID 1001)
- Security hardened
- Multi-platform support
- Health checks included

### 2. Kubernetes Manifests (`k8s/`)

**Base Manifests (`base/`):**
- Namespace
- ServiceAccount + RBAC
- ConfigMap (model configuration)
- Secret (credentials template)
- Deployment (pod spec)
- Service (ClusterIP)
- Route (OpenShift)
- Ingress (Kubernetes)

**Platform Overlays (`overlays/`):**
- `opendatahub/` - OpenDataHub specific configs
- `openshift-ai/` - RHOAI specific configs
- `kubernetes/` - Vanilla K8s configs

### 3. Configuration (`config/`)

- **create-secrets.sh** - Helper script for secrets
- **examples/** - Configuration examples for:
  - Claude via Vertex AI
  - vLLM + Granite
  - Caikit-TGIS + Granite
  - Ollama
  - OpenAI

### 4. Documentation (`docs/`)

- **DEPLOYMENT.md** - Complete deployment guide
- **MODELS.md** - Model configuration reference
- **TROUBLESHOOTING.md** - Common issues & solutions

## ğŸš€ Quick Start

### 1. Build Container Image

```bash
cd docker/
export IMAGE_REGISTRY=quay.io/your-org
./build.sh
```

### 2. Create Secrets

```bash
cd ../config/

# For Claude via Vertex AI
export GOOGLE_PROJECT_ID=your-project-id
kubectl create secret generic chatbot-secrets \
  --from-file=gcp-credentials.json=/path/to/sa.json \
  --from-literal=GOOGLE_PROJECT_ID=${GOOGLE_PROJECT_ID} \
  -n linux-mcp-chatbot
```

### 3. Deploy

```bash
cd ../k8s/

# Standard Kubernetes
kubectl apply -k base/

# Or OpenDataHub
kubectl apply -k overlays/opendatahub/

# Or Red Hat OpenShift AI
oc apply -k overlays/openshift-ai/
```

### 4. Access

```bash
# Port forward
kubectl port-forward -n linux-mcp-chatbot svc/linux-mcp-chatbot 8501:8501

# Open http://localhost:8501
```

## ğŸ”§ Supported Configurations

### Inference Runtimes

| Runtime | Platform | GPU | CPU | Status |
|---------|----------|-----|-----|--------|
| **vLLM** | ODH, RHOAI, K8s | âœ… | âš ï¸ | âœ… Tested |
| **Caikit-TGIS** | RHOAI | âœ… | âœ… | âœ… Tested |
| **TGIS Standalone** | ODH, RHOAI | âœ… | âœ… | âœ… Tested |
| **OpenVINO** | K8s | âš ï¸ | âœ… | âœ… Tested |
| **NVIDIA Triton** | K8s | âœ… | âŒ | âš ï¸ Experimental |
| **Ollama** | K8s | âœ… | âœ… | âœ… Tested |
| **Llama.cpp** | K8s | âŒ | âœ… | âš ï¸ Experimental |
| **Claude (Vertex)** | All | N/A | N/A | âœ… Tested |
| **OpenAI** | All | N/A | N/A | âœ… Tested |

### Models Tested

**Cloud:**
- âœ… Claude 3.5 Sonnet (Vertex AI)
- âœ… GPT-4 Turbo (OpenAI)
- âœ… Gemini 1.5 Pro (Google)

**Self-Hosted:**
- âœ… IBM Granite 7B/13B (vLLM, Caikit-TGIS)
- âœ… Mistral 7B (vLLM, TGIS, Ollama)
- âœ… Meta Llama 3 8B (vLLM, Ollama)
- âœ… Mixtral 8x7B (vLLM)
- âš ï¸ Gemma 2B/7B (OpenVINO, Ollama)
- âš ï¸ DeepSeek Coder 6.7B (vLLM)

## ğŸ“‹ Requirements

### Minimum

- Kubernetes 1.24+ or OpenShift 4.12+
- 2 CPU cores
- 4GB RAM
- kubectl/oc CLI configured

### For Cloud Models

- Google Cloud credentials (Claude)
- OpenAI API key (GPT-4)

### For Self-Hosted Models

**Small Models (< 7B):**
- 1x GPU (16GB VRAM) OR
- 4x CPU cores + 16GB RAM

**Medium Models (7-13B):**
- 1x GPU (24GB VRAM) OR
- 8x CPU cores + 32GB RAM

**Large Models (> 13B):**
- 2-4x GPU (40-80GB VRAM)
- 16x CPU cores + 64GB RAM

## ğŸ” Directory Tree

```
k8s-version/
â”œâ”€â”€ README.md                  # Main documentation
â”œâ”€â”€ OVERVIEW.md                # This file
â”‚
â”œâ”€â”€ docker/                    # Container image
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â””â”€â”€ build.sh               # Build script
â”‚
â”œâ”€â”€ k8s/                       # Kubernetes manifests
â”‚   â”œâ”€â”€ base/                  # Base resources
â”‚   â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”‚   â”œâ”€â”€ serviceaccount.yaml
â”‚   â”‚   â”œâ”€â”€ configmap.yaml     # Model config
â”‚   â”‚   â”œâ”€â”€ secret.yaml
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”œâ”€â”€ route.yaml         # OpenShift
â”‚   â”‚   â”œâ”€â”€ ingress.yaml       # Kubernetes
â”‚   â”‚   â””â”€â”€ kustomization.yaml
â”‚   â”‚
â”‚   â””â”€â”€ overlays/              # Platform-specific
â”‚       â”œâ”€â”€ opendatahub/
â”‚       â”‚   â”œâ”€â”€ kustomization.yaml
â”‚       â”‚   â”œâ”€â”€ configmap-patch.yaml
â”‚       â”‚   â””â”€â”€ deployment-patch.yaml
â”‚       â”œâ”€â”€ openshift-ai/
â”‚       â”‚   â”œâ”€â”€ kustomization.yaml
â”‚       â”‚   â”œâ”€â”€ configmap-patch.yaml
â”‚       â”‚   â””â”€â”€ deployment-patch.yaml
â”‚       â””â”€â”€ kubernetes/
â”‚           â”œâ”€â”€ kustomization.yaml
â”‚           â””â”€â”€ configmap-patch.yaml
â”‚
â”œâ”€â”€ config/                    # Configuration helpers
â”‚   â”œâ”€â”€ create-secrets.sh      # Secret helper
â”‚   â””â”€â”€ examples/              # Example configs
â”‚       â”œâ”€â”€ claude-vertex.env
â”‚       â”œâ”€â”€ vllm-granite.env
â”‚       â”œâ”€â”€ caikit-tgis-granite.env
â”‚       â”œâ”€â”€ ollama.env
â”‚       â””â”€â”€ openai.env
â”‚
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ DEPLOYMENT.md          # How to deploy
    â”œâ”€â”€ MODELS.md              # Model config guide
    â””â”€â”€ TROUBLESHOOTING.md     # Common issues
```

## ğŸ“ Getting Started

### For Beginners

1. **Read:** [README.md](README.md) - Overview and quick start
2. **Choose:** Pick your platform (K8s, ODH, RHOAI)
3. **Configure:** Use an example from `config/examples/`
4. **Deploy:** Follow [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)
5. **Test:** Access chatbot and try a query

### For Experienced Users

1. **Build:** `cd docker/ && ./build.sh`
2. **Secrets:** `cd config/ && ./create-secrets.sh`
3. **Deploy:** `kubectl apply -k k8s/overlays/YOUR_PLATFORM/`
4. **Access:** Port-forward or use Route/Ingress

## ğŸ” Security Features

- âœ… Non-root containers (UID 1001)
- âœ… Security contexts enforced
- âœ… Secrets management (no hardcoded credentials)
- âœ… Read-only root filesystem (where possible)
- âœ… Dropped capabilities
- âœ… Network policies ready
- âœ… RBAC with ServiceAccount
- âœ… SSH key permissions (0600)

## ğŸ“Š Monitoring

Built-in support for:
- Kubernetes health checks (liveness/readiness)
- Prometheus metrics (annotations included)
- Resource usage tracking (requests/limits)
- Log aggregation (stdout/stderr)

## ğŸ”„ Updates

### Update Configuration

```bash
# Edit ConfigMap
kubectl edit configmap chatbot-config -n linux-mcp-chatbot

# Restart deployment
kubectl rollout restart deployment/linux-mcp-chatbot -n linux-mcp-chatbot
```

### Update Container Image

```bash
# Build new version
cd docker/
export IMAGE_TAG=v1.1.0
./build.sh

# Update and redeploy
cd ../k8s/base/
# Edit kustomization.yaml, change newTag
kubectl apply -k .
```

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| [README.md](README.md) | Main documentation, quick start |
| [OVERVIEW.md](OVERVIEW.md) | This file - package overview |
| [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) | Complete deployment guide |
| [docs/MODELS.md](docs/MODELS.md) | Model configuration reference |
| [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md) | Common issues & solutions |

## ğŸ¤ Support

### Common Issues

See [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)

### Getting Help

1. Check pod logs: `kubectl logs -n linux-mcp-chatbot <pod>`
2. Review documentation in `docs/`
3. Test connectivity manually
4. Open issue with logs and configuration

## âœ… Validation Checklist

Before deploying to production:

- [ ] Container image built and pushed
- [ ] Secrets created (credentials, SSH key)
- [ ] ConfigMap updated with model endpoint
- [ ] Resource limits appropriate for load
- [ ] Health checks validated
- [ ] Network policies configured (if needed)
- [ ] Ingress/Route tested
- [ ] SSH to remote hosts working
- [ ] Test query successful
- [ ] Monitoring configured

## ğŸ¯ Next Steps

1. **Deploy your first instance** - Follow [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)
2. **Configure your model** - See [docs/MODELS.md](docs/MODELS.md)
3. **Test thoroughly** - Try example queries
4. **Scale if needed** - Add HPA, increase replicas
5. **Monitor** - Set up Prometheus, logs
6. **Secure** - Add NetworkPolicies, TLS

---

**Ready to deploy AI-powered Linux diagnostics in Kubernetes!** ğŸš€
